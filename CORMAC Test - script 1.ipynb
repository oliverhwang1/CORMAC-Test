{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cms_procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assume the number of procedure ids /observations in the dataset is n (which is an integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The outputs for these three functions are like:\n",
    "\n",
    "#### a. get_procedure_attributes(procedure_id = None) \n",
    "= {'procedure_id': value1, 'type of procedure': value2, 'how long it lasted' : value3, 'severity of the condition being addressed' : value4}\n",
    "\n",
    "\n",
    "#### b. get_procedure_success(procedure_id) \n",
    "\n",
    "= 'True' / \"False' (returns True if the procedure succeeded and False otherwise('outcome' : \"Success\"/\"Failure\"))\n",
    "\n",
    "\n",
    "\n",
    "#### c. get_procedure_outcomes(procedure_id) \n",
    "\n",
    "= more granular measures of the outcome\n",
    "\n",
    "= {'severity of post procedure complications' : value1 , 'pain', value2, 'recurrence of original condition': value3}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data using the specified API (three functions):\n",
    "\n",
    "#lists of attributes:\n",
    "Procedure_ids, Type_of_procedure, How_long_it_lasted, Severity_of_the_condition_being_addressed  = [], [], [], []\n",
    "\n",
    "#lists of outcomes:\n",
    "Severity_of_post_procedure_complications, Pain, Recurrence_of_original_condition = [], [], []\n",
    "\n",
    "#list of the outcome(True/False) of procedures:\n",
    "Outcomes = []\n",
    "\n",
    "\n",
    "while len(Procedure_ids) <= n:# where n is the number of procedure ids / observations in the dataset by my assumption initially\n",
    "\n",
    "    procedure_id = get_procedure_attributes(procedure_id = None)['procedure_id']\n",
    "    if procedure_id not in Procedure_ids:\n",
    "        Procedure_ids.append(procedure_id)\n",
    "        Type_of_procedure.append(get_procedure_attributes(procedure_id)['type of procedure'])\n",
    "        How_long_it_lasted.append(get_procedure_attributes(procedure_id)['how long it lasted'])\n",
    "        Severity_of_the_condition_being_addressed.append(get_procedure_attributes(procedure_id)['severity of the condition being addressed'])\n",
    "\n",
    "        Severity_of_post_procedure_complications.append(get_procedure_outcomes(procedure_id)['severity of post procedure complications'])\n",
    "        Pain.append(get_procedure_outcomes(procedure_id)['pain'])\n",
    "        Recurrence_of_original_condition.append(get_procedure_outcomes(procedure_id)['recurrence of original condition'])            \n",
    "\n",
    "        Outcomes.append(get_procedure_success(procedure_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe using the data polled out above:\n",
    "\n",
    "d = {'procedure_id': Procedure_ids, 'type of procedure': Type_of_procedure, 'how long it lasted': How_long_it_lasted, 'severity of the condition being addressed': Severity_of_the_condition_being_addressed,\n",
    "    'severity of post procedure complications': Severity_of_post_procedure_complications, 'pain': Pain, 'recurrence of original condition': Recurrence_of_original_condition, 'outcome': Outcomes}\n",
    "\n",
    "df = pd.DataFrame(data = d)\n",
    "\n",
    "# Dealing with missing values:\n",
    "\n",
    "#if the percentage of missing values in the dataframe is not so high(< 30%), we chose to drop those:\n",
    "if len(df.dropna())/len(df) > 0.7:\n",
    "    new_df = df.dropna()\n",
    "    \n",
    "#otherwise, only keep the columns having less missing values with threshold 30% for each column:\n",
    "else:  \n",
    "    missing_values_perc = df.isnull().sum()/len(df) # saving missing values' percentages of different columns\n",
    "    new_variables = [ ]\n",
    "    for i in range(len(df.columns)):\n",
    "        if missing_values_perc[i] < 0.3: # threshold 30%\n",
    "            new_variables.append(df.columns[i])\n",
    "    new_df = df[new_variables]\n",
    "\n",
    "\n",
    "#replace 'False' and 'True' in the labels - 'outcome' by 0 and 1 respectively:\n",
    "\n",
    "new_df['outcome'] = new_df['outcome'].apply(lambda x: 0 if x == 'False' else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = new_df[\"outcome\"]\n",
    "procedure_ids = new_df[\"procedure_id\"]\n",
    "\n",
    "#features X:\n",
    "X = df.drop(columns = ['procedure_id', 'outcome'], axis = 1)\n",
    "\n",
    "# Changing categorical variables in features X into dummy variables:\n",
    "\n",
    "string_variables = []\n",
    "for i in range(new_df.columns):\n",
    "    if not float(new_df[i][0]): # if the column's type is string, I transfer the variable into dummies variables\n",
    "        X = pd.get_dummies(X,columns = [i])\n",
    "        string_variables.append(i)\n",
    "    \n",
    "X_features = X.columns # all features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature evaluation using Logistic Regression model with Minimum AIC\n",
    "\n",
    " - I am going to find a model with the minimum AIC. \n",
    " - I first split the data into training and test, use the training data to select variables to include in the model, and then estimate the model parameters on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns a logistic regression model with the minimum AIC\n",
    "def minAIC_Logit(X,y):\n",
    "    variables = X.columns\n",
    "    model = sm.Logit(y,X[variables]).fit()\n",
    "    while True:\n",
    "        print(f'old model aic: {model.aic}')\n",
    "        maxp = np.max(model.pvalues)\n",
    "        newvariables = variables[model.pvalues < maxp]\n",
    "        removed = variables[model.pvalues == maxp].values\n",
    "        print(f'considering a model with these variables removed: {removed}')\n",
    "        newmodel = sm.Logit(y,X[newvariables]).fit()\n",
    "        print(f'new model aic: {newmodel.aic}')\n",
    "        if newmodel.aic < model.aic:\n",
    "            model = newmodel\n",
    "            variables = newvariables\n",
    "        else:\n",
    "            break\n",
    "    return model,variables\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=2)\n",
    "\n",
    "# now call the minAIC function on the predictors and response variables\n",
    "new_train_model, logit_variables = minAIC_Logit(X_train.astype(float), y_train)\n",
    "\n",
    "# Now fit the variables selected, using the test data\n",
    "new_model = sm.Logit(y_train, X_train[logit_variables]).fit()\n",
    "results = new_model.summary()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_test_all_pred = sm.Logit(y_test,X_test).fit().aic, \n",
    "\n",
    "AIC_test_selected_pred = sm.Logit(y_test,X_test[logit_variables]).fit().aic, \n",
    "\n",
    "AIC_test_all_pred, AIC_test_selected_pred\n",
    "#the AIC is supposed to decrease when using logit_variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and modeling evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X[logit_variables], labels, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RandomForest Classifier:\n",
    " - Reasons: \n",
    "     1. this classifier algorithm can overcome the overfitting problem in decision trees;\n",
    "     2. it works good for both categorical and continuous values.\n",
    "     3. it can automatically handle missing values in the data.\n",
    "     \n",
    "     \n",
    " - In order to get a good model, we need to tune the hyper-parameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### rfc is the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = float('-inf')\n",
    "estimator = 0\n",
    "for i in range(100,3000,50):\n",
    "    rfc = RandomForestClassifier(random_state=42,n_estimators=i)\n",
    "    cv = cross_val_score(rfc,X_train,y_train,cv=5,scoring='accuracy')\n",
    "    if cv > cvs:\n",
    "        cvs = cv\n",
    "        estimator = i\n",
    "\n",
    "        \n",
    "rfc = RandomForestClassifier(random_state=42,n_estimators=estimator)\n",
    "rfc = rfc.fit(X_train,y_train) # rfc is the trained model\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import f1_score\n",
    "score = 100 * metrics.f1_score(y_test, predictions)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
